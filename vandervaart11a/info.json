{
    "abstract": "We consider the quality of learning a response function by a nonparametric Bayesian approach using a Gaussian process (GP) prior on the response function. We upper bound the quadratic risk of the learning procedure, which in turn is an upper bound on the Kullback-Leibler information between the predictive and true data distribution. The upper bound is expressed in small ball probabilities and concentration measures of the GP prior.  We illustrate the computation of the upper bound for the Mat{{\\'e}}rn  and squared exponential kernels.  For these priors the risk, and hence the information criterion, tends to zero for all continuous response functions. However, the rate at which this happens depends on the combination of true response function and Gaussian prior, and is expressible in a certain concentration function. In particular, the results show that for good performance, the regularity of the GP prior should match the regularity of the unknown response function.",
    "authors": [
        "Aad van der Vaart",
        "Harry van Zanten"
    ],
    "id": "vandervaart11a",
    "issue": 59,
    "pages": [
        2095,
        2119
    ],
    "title": "Information Rates of Nonparametric Gaussian Process Methods",
    "volume": "12",
    "year": "2011"
}